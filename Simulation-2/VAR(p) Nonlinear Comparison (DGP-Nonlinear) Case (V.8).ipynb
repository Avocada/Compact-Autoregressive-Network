{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.linalg import svd\n",
    "import numpy as np    \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from time import perf_counter \n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = 2\n",
    "r2 = 2\n",
    "r3 = 2 \n",
    "p = 3\n",
    "N = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \"Construct a Deep Network for Nonlinearity\n",
    "\n",
    "class NetDW(nn.Module):\n",
    "\n",
    "    def __init__(self, r1, r2, r3, p, N):\n",
    "        \n",
    "        self.r1 = r1\n",
    "        self.r2 = r2\n",
    "        self.r3 = r3\n",
    "        self.p = p\n",
    "        self.N = N\n",
    "        super(NetDW, self).__init__()\n",
    "        # .conv1: 1 input matrix channel (N*P), r2 output channels, Nx1 convolution kernel\n",
    "        # .conv2: 1 input matrix channel (1*P), r3 output channels, 1xr3 convolution kernel (kernel sharing)\n",
    "        self.conv1 = nn.Conv2d(1, r2, kernel_size=(N, 1), bias=False) # stride is set to be (0,1) -> only move to the right\n",
    "        self.conv2 = nn.Conv2d(1, r3, kernel_size=(1, p), bias=False)   # stride is set to be 0 -> no moving needed\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(in_features=r2*r3, out_features=r1, bias=False)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(in_features=r1, out_features=N, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = F.relu(self.conv1(x))\n",
    "        y2 = F.relu(self.conv2(x))\n",
    "        # first N, then p\n",
    "        z1 = self.conv2(y1[:, :1, :, :])\n",
    "        for i in range(1, y1.shape[1]):\n",
    "            z1 = torch.cat([z1, self.conv2(y1[:, i:(i+1), :, :])], dim = 1) #Flattening is achieved     \n",
    "            z1 = F.relu(z1.view(-1, self.r2*self.r3)) #-1 helps us figure out the batchsize\n",
    "        # first p, then N\n",
    "        z2 = F.relu(self.conv1(y2[:, :1, :, :]))\n",
    "        for i in range(1, y2.shape[1]):\n",
    "            z2 = torch.cat([z2, self.conv1(y2[:, i:(i+1), :, :])], dim = 2) #Flattening is achieved     \n",
    "            z2 = F.relu(z2.view(-1, self.r2*self.r3)) #-1 helps us figure out the batchsize\n",
    "        x1 = self.fc2(F.relu(self.fc1(z1)))\n",
    "        x2 = self.fc2(F.relu(self.fc1(z2)))\n",
    "        x = torch.stack([x1,x2])\n",
    "        x = torch.mean(x,dim=0)\n",
    "        return x\n",
    "\n",
    "class NetRelu(nn.Module):\n",
    "\n",
    "    def __init__(self, r1, r2, r3, p, N):\n",
    "        \n",
    "        self.r1 = r1\n",
    "        self.r2 = r2\n",
    "        self.r3 = r3\n",
    "        self.p = p\n",
    "        self.N = N\n",
    "        super(NetRelu, self).__init__()\n",
    "        # .conv1: 1 input matrix channel (N*P), r2 output channels, Nx1 convolution kernel\n",
    "        # .conv2: 1 input matrix channel (1*P), r3 output channels, 1xr3 convolution kernel (kernel sharing)\n",
    "        self.conv1 = nn.Conv2d(1, r2, kernel_size=(N, 1), bias=False) # stride is set to be (0,1) -> only move to the right\n",
    "        self.conv2 = nn.Conv2d(1, r3, kernel_size=(1, p), bias=False)   # stride is set to be 0 -> no moving needed\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(in_features=r2*r3, out_features=r1, bias=False)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(in_features=r1, out_features=N, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.relu(self.conv1(x))\n",
    "        z = self.conv2(x[:, :1, :, :])\n",
    "        for i in range(1, x.shape[1]):\n",
    "            z = torch.cat([z, self.conv2(x[:, i:(i+1), :, :])], dim = 1) #Flattening is achieved     \n",
    "        z = F.relu(z.view(-1, self.r2*self.r3)) #-1 helps us figure out the batchsize\n",
    "        x = F.relu(self.fc1(z)) #activation can be added on the inside as well\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class NetLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, r1, r2, r3, p, N):\n",
    "        \n",
    "        self.r1 = r1\n",
    "        self.r2 = r2\n",
    "        self.r3 = r3\n",
    "        self.p = p\n",
    "        self.N = N\n",
    "        super(NetLinear, self).__init__()\n",
    "        # .conv1: 1 input matrix channel (N*P), r2 output channels, Nx1 convolution kernel\n",
    "        # .conv2: 1 input matrix channel (1*P), r3 output channels, 1xr3 convolution kernel (kernel sharing)\n",
    "        self.conv1 = nn.Conv2d(1, r2, kernel_size=(N, 1), bias=False) # stride is set to be (0,1) -> only move to the right\n",
    "        self.conv2 = nn.Conv2d(1, r3, kernel_size=(1, p), bias=False)   # stride is set to be 0 -> no moving needed\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(in_features=r2*r3, out_features=r1, bias=False)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(in_features=r1, out_features=N, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = self.conv1(x)\n",
    "        z = self.conv2(x[:, :1, :, :])\n",
    "        for i in range(1, x.shape[1]):\n",
    "            z = torch.cat([z, self.conv2(x[:, i:(i+1), :, :])], dim = 1) #Flattening is achieved     \n",
    "        z = z.view(-1, self.r2*self.r3) #-1 helps us figure out the batchsize\n",
    "        x = self.fc1(z) #activation can be added on the inside as well\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \"Define Custom Nonlinear Acivation Function\n",
    "\n",
    "def nonLFunc(a):\n",
    "    '''\n",
    "    Applies customize nonlinear transformation to the entries of the input matrix\n",
    "    '''\n",
    "    return torch.cos(1/torch.sqrt(torch.sum(a**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \"Nonlinear data generating process\n",
    "\n",
    "def kronecker(A, B):\n",
    "    return torch.ger(A.view(-1), B.view(-1)).reshape(*(A.size() + B.size())).permute([0, 2, 1, 3]).reshape(A.size(0)*B.size(0),A.size(1)*B.size(1))\n",
    "\n",
    "class L2LossFun(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(L2LossFun, self).__init__()\n",
    "    def forward(self, A_Est, A_True):\n",
    "        gap = math.sqrt(torch.sum((A_Est - A_True)**2))\n",
    "        return gap\n",
    "    \n",
    "def genU(x, y, r, trans):\n",
    "            # x, y-stands for the size of the random matrix\n",
    "            # r stands for the numbers of dimensions to keep\n",
    "            # trans is a bool to judge whether to transpose or not\n",
    "    URM = torch.randn(x, y)\n",
    "    U, s, VT = svd(URM)\n",
    "    if trans == True:\n",
    "        Us = torch.tensor(np.transpose(U[:,:r]))\n",
    "    else:\n",
    "        Us = torch.tensor(U[:,:r])\n",
    "    return Us\n",
    "\n",
    "def encoderDecoder(x, r2, r3, U1, G1, U2T, U3):\n",
    "    encoder = torch.mm(U2T, torch.mm((torch.randn(N, p)), U3))\n",
    "    encoderNL = nonLFunc(encoder).view(1,1)\n",
    "    y = torch.squeeze(torch.mm(torch.mm(U1, G1), encoderNL))    \n",
    "    return y\n",
    "\n",
    "class RandomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, r1, r2, r3, p, N, Smp_size, U1, G1, U2T, U3):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        for i in range(Smp_size+500):\n",
    "            if i == 0:\n",
    "                input_TS = torch.randn(1, 1, N, p)\n",
    "                input_TS = torch.squeeze(input_TS.view(1,1,N,p))\n",
    "                self.X.append(input_TS)\n",
    "                output_TS =encoderDecoder(input_TS, r2, r3, U1, G1, U2T, U3)\n",
    "                self.y.append(output_TS[:N] + torch.randn(N))  \n",
    "            else:\n",
    "                input_TS = torch.cat([self.y[i-1].view(N,1), input_TS], dim = 1)\n",
    "                self.X.append(input_TS[:N,:p])\n",
    "                out_tmp = encoderDecoder(input_TS[:N,:p], r2, r3, U1, G1, U2T, U3)\n",
    "                self.y.append(out_tmp[:N] + torch.randn(N))\n",
    "        self.X = self.X[500:]\n",
    "        self.y = self.y[500:]\n",
    "                \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input to GPU\n",
    "#device = torch.device(\"cuda:2\")\n",
    "#device2 = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "Smp_size = 500\n",
    "\n",
    "# initialize dict with dynamic list for storage\n",
    "names = {}\n",
    "names[\"y_true\"] = []\n",
    "names[\"predErrorDW\" + str(Smp_size)] =  []\n",
    "names[\"y_predDW\"] = []\n",
    "names[\"predErrorN\" + str(Smp_size)] =  []\n",
    "names[\"y_predN\"] = []\n",
    "names[\"predErrorL\" + str(Smp_size)] =  []\n",
    "names[\"y_predL\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amy/.virtualenvs/dl4cv/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/amy/.virtualenvs/dl4cv/lib/python3.6/site-packages/ipykernel_launcher.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredError is 0.34976304144486114.\n",
      "PredError for N is 0.34976304144486114.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amy/.virtualenvs/dl4cv/lib/python3.6/site-packages/ipykernel_launcher.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredError for L is 0.3412525073973356.\n",
      "0\n",
      "PredError is 0.27480523351003416.\n",
      "PredError for N is 0.7316438995083674.\n",
      "PredError for L is 0.7704171628573304.\n",
      "1\n",
      "PredError is 1.763484061065503.\n",
      "PredError for N is 0.8914315154734398.\n",
      "PredError for L is 0.8224690583169778.\n",
      "2\n",
      "PredError is -0.34377171054243494.\n",
      "PredError for N is -0.22155165634302953.\n",
      "PredError for L is -0.2318920162703071.\n",
      "3\n",
      "PredError is 0.4768795950127114.\n",
      "PredError for N is 0.6232203741360367.\n",
      "PredError for L is 0.700155409986472.\n",
      "4\n",
      "PredError is -0.3212596087665247.\n",
      "PredError for N is -0.3212596087665247.\n",
      "PredError for L is -0.3316110201575686.\n",
      "5\n",
      "PredError is 0.22833176390397636.\n",
      "PredError for N is 0.18414602665036472.\n",
      "PredError for L is 0.21873008130321114.\n",
      "6\n",
      "PredError is -0.1536586678968872.\n",
      "PredError for N is 0.02232735382215001.\n",
      "PredError for L is -0.06232114705360914.\n",
      "7\n",
      "PredError is 0.349379045333607.\n",
      "PredError for N is 0.3093018722662215.\n",
      "PredError for L is 0.058222718053218436.\n",
      "8\n",
      "PredError is 0.20673746709679364.\n",
      "PredError for N is 1.090659585446474.\n",
      "PredError for L is 0.13125117461066793.\n",
      "9\n",
      "PredError is 0.09020666905734043.\n",
      "PredError for N is -0.6627742447277125.\n",
      "PredError for L is -0.6618356735237958.\n",
      "10\n",
      "PredError is 0.8763270401179915.\n",
      "PredError for N is 0.9115402507287662.\n",
      "PredError for L is 0.9316724588584364.\n",
      "11\n",
      "PredError is -0.13352969143341475.\n",
      "PredError for N is -0.16480838938342046.\n",
      "PredError for L is 0.024314317371198158.\n",
      "12\n",
      "PredError is -0.8772420329341566.\n",
      "PredError for N is -0.7609692932938712.\n",
      "PredError for L is -0.7711262420712952.\n",
      "13\n",
      "PredError is 1.2734791527454394.\n",
      "PredError for N is 1.2735119882914328.\n",
      "PredError for L is 1.1436446436000782.\n",
      "14\n",
      "PredError is -0.3099911092423566.\n",
      "PredError for N is -0.3099911092423566.\n",
      "PredError for L is -0.4329146342778998.\n",
      "15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-afeea1608dd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m#=======backward pass=====================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mloss_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t1_start = perf_counter() \n",
    "\n",
    "distance = L2LossFun()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for iter in range(200):\n",
    "    U3 = genU(p, p, r3, False)\n",
    "    U2T = genU(N, N, r2, True)\n",
    "    G1 =  F.normalize(torch.randn(r1, 1), p=2, dim=0)*0.9 # norm of G is fixed to be 0.95 -> l2 operator norm\n",
    "    U1 = genU(N, N, r1, False)\n",
    "    ds = RandomDataset(r1=r1, r2=r2, r3=r3, p=p, N=N, Smp_size=Smp_size, U1=U1, G1=G1, U2T=U2T, U3=U3)\n",
    "    ### Generate one-step ahead forecast value\n",
    "    X_t, y_t = ds[Smp_size-1]\n",
    "    X_F = torch.cat([y_t.view(1,1,N,1), X_t.view(1,1,N,p)], dim = 3)[:,:,:N,:p]\n",
    "    y_F = encoderDecoder(torch.squeeze(X_F), r2, r3, U1, G1, U2T, U3) + torch.randn(N)\n",
    "    \n",
    "    ds = DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    ### \"\"NetDW\n",
    "    netDW = NetDW(r1, r2, r3, p, N)\n",
    "    optimizer = optim.SGD(netDW.parameters(), lr = 0.01, momentum=0.9)\n",
    "    loss_last = 1000\n",
    "    loss_new = 0\n",
    "    \n",
    "    i = 0\n",
    "    while abs(loss_last - loss_new) > 0.000000001:\n",
    "        if i > 0:\n",
    "            loss_last = loss_new  \n",
    "        for ix, (_x, _y) in enumerate(ds):\n",
    "            _x = _x.view(Smp_size,1,N,p)\n",
    "            #=========make inpur differentiable=======================\n",
    "            _x = Variable(_x).float()\n",
    "            #_x = _x.to(device)\n",
    "            _y = torch.squeeze(Variable(_y).float())\n",
    "            #_y = _y.to(device)\n",
    "            #========forward pass=====================================\n",
    "            yhat = netDW(_x).float()\n",
    "            loss = criterion(yhat, _y)\n",
    "            #=======backward pass=====================================\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            loss_new = loss.item()\n",
    "        i = i + 1\n",
    "        \n",
    "    X_F = Variable(X_F).float()\n",
    "    #X_F = X_F.to(device)\n",
    "    y_F = torch.tensor(Variable(y_F).float())\n",
    "    #y_F = y_F.to(device)\n",
    "    names[\"y_true\"].append(y_F)\n",
    "    y_predDW = netDW(X_F).float()\n",
    "    predErrorDW = distance(y_predDW, y_F) - np.sqrt(N)\n",
    "    print(\"PredError is {}.\".format(predErrorDW))\n",
    "    names[\"predErrorDW\" + str(Smp_size)].append(predErrorDW)\n",
    "    names[\"y_predDW\"].append(y_predDW)\n",
    "    ### \"\"NetN\n",
    "    netN = NetRelu(r1, r2, r3, p, N)\n",
    "    optimizerN = optim.SGD(netN.parameters(), lr = 0.01, momentum=0.9)\n",
    "    loss_last = 1000\n",
    "    loss_new = 0\n",
    "    \n",
    "    i = 0\n",
    "    while abs(loss_last - loss_new) > 0.00000001:\n",
    "        if i > 0:\n",
    "            loss_last = loss_new  \n",
    "        for ix, (_x, _y) in enumerate(ds):\n",
    "            _x = _x.view(Smp_size,1,N,p)\n",
    "            #=========make inpur differentiable=======================\n",
    "            _x = Variable(_x).float()\n",
    "            #_x = _x.to(device)\n",
    "            _y = torch.squeeze(Variable(_y).float())\n",
    "            #_y = _y.to(device)\n",
    "            #========forward pass=====================================\n",
    "            yhat = netN(_x).float()\n",
    "            loss = criterion(yhat, _y)\n",
    "            #=======backward pass=====================================\n",
    "            optimizerN.zero_grad() \n",
    "            loss.backward() \n",
    "            optimizerN.step() \n",
    "            loss_new = loss.item()\n",
    "        i = i + 1\n",
    "        \n",
    "    X_F = Variable(X_F).float()\n",
    "    #X_F = X_F.to(device)\n",
    "    y_F = torch.tensor(Variable(y_F).float())\n",
    "    #y_F = y_F.to(device)\n",
    "    y_predN = netN(X_F).float()\n",
    "    predErrorN = distance(y_predN, y_F) - np.sqrt(N)\n",
    "    print(\"PredError for N is {}.\".format(predErrorN))\n",
    "    names[\"predErrorN\" + str(Smp_size)].append(predErrorN)\n",
    "    names[\"y_predN\"].append(y_predN)\n",
    "    ### \"\"FC\n",
    "    netLinear = NetLinear(r1, r2, r3, p, N)\n",
    "    optimizerL = optim.SGD(netLinear.parameters(), lr = 0.01, momentum=0.9)\n",
    "    \n",
    "    loss_last = 1000\n",
    "    loss_new = 0\n",
    "\n",
    "    i = 0\n",
    "    while abs(loss_last - loss_new) > 0.00000001:\n",
    "        if i > 0:\n",
    "            loss_last = loss_new  \n",
    "        for ix, (_x, _y) in enumerate(ds):\n",
    "            _x = Variable(_x.view(Smp_size,1,N,p)).float()\n",
    "            #_x = _x.to(device)\n",
    "            _y = torch.squeeze(Variable(_y).float())\n",
    "            #_y = _y.to(device)\n",
    "            yhat = netLinear(_x).float()\n",
    "            loss = criterion(yhat, _y)\n",
    "            optimizerL.zero_grad() \n",
    "            loss.backward() \n",
    "            optimizerL.step()\n",
    "            loss_new = loss.item()\n",
    "        i = i + 1\n",
    "\n",
    "    X_F = Variable(X_F.view(1,1,N,p)).float()\n",
    "    #X_F = X_F.to(device)\n",
    "    y_F = torch.tensor(Variable(y_F).float())\n",
    "    #y_F = y_F.to(device)\n",
    "    y_predL = netLinear(X_F).float()\n",
    "    predErrorL = distance(y_predL, y_F) - np.sqrt(N)\n",
    "    print(\"PredError for L is {}.\".format(predErrorL))\n",
    "    names[\"predErrorL\" + str(Smp_size)].append(predErrorL)\n",
    "    names[\"y_predL\"].append(y_predL)\n",
    "    print(iter)\n",
    "\n",
    "t1_stop = perf_counter() \n",
    "print(\"Elapsed time during the whole program in seconds:\", \n",
    "                                        t1_stop-t1_start) \n",
    "sim500_r2P3N25 = names\n",
    "torch.save(sim500_r2P3N25, \"sim500_r2P3N25.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2343712655295302\n",
      "0.24663697537569995\n",
      "0.16565179993752815\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, median\n",
    "print(mean(names[\"predErrorDW\" + str(Smp_size)]))\n",
    "print(mean(names[\"predErrorN\" + str(Smp_size)]))\n",
    "print(mean(names[\"predErrorL\" + str(Smp_size)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
