{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from time import perf_counter \n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "torch.set_num_threads(40)\n",
    "def to_torch(state):\n",
    "    state = torch.from_numpy(state).float()\n",
    "    return state\n",
    " \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, p, q, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "        self.hidden_dim = q\n",
    "        self.feature_size = p\n",
    "        self.output_size = output_size\n",
    "        self.rnn = nn.RNN(self.feature_size, self.hidden_dim)\n",
    "        self.hidden2output = nn.Linear(self.hidden_dim, output_size)\n",
    " \n",
    "    def forward(self, input_y, h = None):  \n",
    "        samples = input_y\n",
    "        rnn_out, last_rnn_hidden = self.rnn(samples, h)\n",
    "        output = self.hidden2output(rnn_out.view(-1, self.hidden_dim))\n",
    "        return output.view(samples.shape[0],samples.shape[1],self.output_size), last_rnn_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \" F-norm of A\n",
    "class L2LossFun(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(L2LossFun, self).__init__()\n",
    "    def forward(self, A_Est, A_True):\n",
    "        gap = math.sqrt(np.sum((A_Est - A_True)**2))\n",
    "        return gap\n",
    "\n",
    "class LinfLossFun(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinfLossFun, self).__init__()\n",
    "    def forward(self, A_Est, A_True):\n",
    "        gap = np.max(np.abs(A_Est-A_True))\n",
    "        return gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfP = pd.read_csv(\"deseason.csv\") \n",
    "df = np.array(dfP)[0:301,0:50]\n",
    "### \"Data preprocessing\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "N = 50\n",
    "output_size = 50\n",
    "Smp_size = 200\n",
    "q = 1 #hidden dimension\n",
    "lag = 30\n",
    "Pred_size = len(df)-Smp_size - lag\n",
    "# the layer is set to be 1 and fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {}\n",
    "names[\"predErrorRNN1\"] =  []\n",
    "names[\"predErrorRNN1Linf\"] =  []\n",
    "names[\"LTRRNN1_pred\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "# initialization\n",
    "p , q, output_size = (N, 1, N)\n",
    "\n",
    "# transform the time series involving\n",
    "def create_dataset(y, look_back=1):\n",
    "    dataYp,dataYc = [], [] #Ypast, Ycurrent\n",
    "    for i in range(len(y)-look_back):\n",
    "        dataYp.append(y[i,:])\n",
    "        dataYc.append(y[i+look_back, :])\n",
    "    return np.array(dataYp), np.array(dataYc)\n",
    " \n",
    "# transform data to tensor in torch\n",
    "def to_torch(state):\n",
    "    state = torch.from_numpy(state).float()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredError is 0.7807243748980223.\n",
      "PredErrorLinf is 0.34701550426341954.\n",
      "0\n",
      "PredError is 0.9815096515294646.\n",
      "PredErrorLinf is 0.5347384810447693.\n",
      "1\n",
      "PredError is 0.8194143691737582.\n",
      "PredErrorLinf is 0.5035070031354496.\n",
      "2\n",
      "PredError is 0.73367894035939.\n",
      "PredErrorLinf is 0.3572332358003092.\n",
      "3\n",
      "PredError is 0.5218246818505494.\n",
      "PredErrorLinf is 0.19556096719426852.\n",
      "4\n",
      "PredError is 0.656994080011507.\n",
      "PredErrorLinf is 0.37488406786688416.\n",
      "5\n",
      "PredError is 0.6847873046831742.\n",
      "PredErrorLinf is 0.3520090572403242.\n",
      "6\n",
      "PredError is 1.0464269194042644.\n",
      "PredErrorLinf is 0.4824884994277545.\n",
      "7\n",
      "PredError is 0.7750425662764038.\n",
      "PredErrorLinf is 0.32513271833340335.\n",
      "8\n",
      "PredError is 0.5169388542178093.\n",
      "PredErrorLinf is 0.19432368022184293.\n",
      "9\n",
      "Elapsed time during the whole program in seconds: 219.79331761600042\n"
     ]
    }
   ],
   "source": [
    "distance = L2LossFun()\n",
    "distanceLinf = LinfLossFun()\n",
    "\n",
    "t1_start = perf_counter() \n",
    "\n",
    "for k in range(pred_size):\n",
    "    y = df[(Smp_size+k+lag-200):(Smp_size+k+lag+1),:] #Fixed size at 200!\n",
    "    inY, outY = create_dataset(y=y, look_back=1) \n",
    "    # split into train and test sets\n",
    "    train_size = 200                                  #Fixed size at 200!\n",
    "    test_size = 1\n",
    "    trainInY,trainOutY = inY[0:train_size-1], outY[0:train_size-1]\n",
    "    testInY,testOutY =  inY[train_size-1:], outY[train_size-1:]\n",
    "    trainInY = np.reshape(trainInY, (trainInY.shape[0], 1, p))\n",
    "    trainOutY = np.reshape(trainOutY, (trainOutY.shape[0], 1, p))\n",
    "    testInY = np.reshape(testInY, (testInY.shape[0], 1, p))\n",
    "    testOutY = np.reshape(testOutY, (testOutY.shape[0], 1, p))\n",
    "\n",
    "    model = RNN(p = N,q = 1, output_size = output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "    loss_last = 1000\n",
    "    loss_new = 0\n",
    "\n",
    "    i = 0\n",
    "    while abs(loss_last - loss_new)  > 0.000001:\n",
    "        if i > 0:\n",
    "            loss_last = loss_new  \n",
    "\n",
    "        model.zero_grad()\n",
    "        target = torch.from_numpy(trainOutY).float()\n",
    "        output,_ = model(torch.from_numpy(trainInY).float())\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output, h = model(torch.from_numpy(trainInY).float())\n",
    "        loss_new = loss.item()\n",
    "        i = i + 1\n",
    "        #print(loss_new)\n",
    "    testPredict,_ = model(torch.from_numpy(testInY).float(), h)\n",
    "    testPredict = testPredict.detach().numpy()\n",
    "    # invert predictions\n",
    "    #testPredict_r = scaler.inverse_transform(testPredict[:,0, :])\n",
    "    #testY_r = scaler.inverse_transform(testOutY[:,0,:])\n",
    "    testPredict = testPredict[:,0, :]\n",
    "    testOutY = testOutY[:,0,:]\n",
    "    names[\"LTRRNN1_pred\"].append(testPredict)\n",
    "    predError = distance(testPredict, testOutY)\n",
    "    names[\"predErrorRNN1\"].append(predError)\n",
    "    print(\"PredError is {}.\".format(predError))\n",
    "    predErrorLinf = distanceLinf(testPredict, testOutY)\n",
    "    names[\"predErrorRNN1Linf\"].append(predErrorLinf)\n",
    "    print(\"PredErrorLinf is {}.\".format(predErrorLinf))\n",
    "    \n",
    "    print(k)\n",
    "\n",
    "t1_stop = perf_counter() \n",
    "print(\"Elapsed time during the whole program in seconds:\", \n",
    "                                        t1_stop-t1_start) \n",
    "Real_200RNN1s = names\n",
    "torch.save(Real_200RNN1s, \"Real_200RNN1s.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
