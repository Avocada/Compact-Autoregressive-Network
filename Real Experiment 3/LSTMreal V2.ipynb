{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from time import perf_counter \n",
    "torch.set_num_threads(30)\n",
    "class LSTMcell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_size):\n",
    "        super(LSTMcell, self).__init__()\n",
    "        self.hidden_size = hidden_dim\n",
    "        self.output_size = output_size\n",
    "        # nn.Linear(in_features, out_features, bias=True)\n",
    "        self.cgate = nn.Linear(input_dim + hidden_dim, hidden_dim)\n",
    "        self.igate = nn.Linear(input_dim + hidden_dim, hidden_dim)\n",
    "        self.fgate = nn.Linear(input_dim + hidden_dim, hidden_dim)\n",
    "        self.ogate = nn.Linear(input_dim + hidden_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_size)\n",
    "        # Activation functions\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, sample, hidden = None, cellstate = None):\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros(1, self.hidden_size, dtype=sample.dtype, device=sample.device)\n",
    "        if cellstate is None:\n",
    "            cellstate = torch.zeros(1, self.hidden_size)\n",
    "\n",
    "        combined = torch.cat((sample, hidden), 1)\n",
    "\n",
    "        f_gate = self.sigmoid(self.fgate(combined))\n",
    "        i_gate = self.sigmoid(self.igate(combined))\n",
    "        o_gate = self.sigmoid(self.ogate(combined))\n",
    "        c_tilde = self.tanh(self.cgate(combined))\n",
    "\n",
    "        first = torch.mul(cellstate, f_gate)\n",
    "        second = torch.mul(c_tilde, i_gate)\n",
    "        cell = torch.add(first, second)\n",
    "\n",
    "        hidden = torch.mul(self.tanh(cell), o_gate)\n",
    "        output = self.output(hidden)\n",
    "        # output = self.sigmoid(output)\n",
    "        return output, hidden, cell\n",
    "    \n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, p, q, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "\n",
    "        self.hidden_dim = q\n",
    "        self.feature_size = p\n",
    "        self.output_size = output_size\n",
    "        self.lstm = LSTMcell(self.feature_size, self.hidden_dim, self.output_size)\n",
    " \n",
    "    def forward(self, input_y, h_0 = None, c_0 = None):      \n",
    "        time_steps = input_y.shape[0]\n",
    "        outputs = torch.Tensor(time_steps, self.output_size)\n",
    "        samples = input_y\n",
    "        for t in range(time_steps):\n",
    "            tmp, c, h = self.lstm(samples[t,:].reshape(1,-1), h_0, c_0)\n",
    "            outputs[t, :] = tmp.view(-1,self.output_size)\n",
    "        return outputs, c, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \" F-norm of A\n",
    "class L2LossFun(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(L2LossFun, self).__init__()\n",
    "    def forward(self, A_Est, A_True):\n",
    "        gap = math.sqrt(np.sum((A_Est - A_True)**2))\n",
    "        return gap\n",
    "\n",
    "class LinfLossFun(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinfLossFun, self).__init__()\n",
    "    def forward(self, A_Est, A_True):\n",
    "        gap = np.max(np.abs(A_Est-A_True))\n",
    "        return gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfP = pd.read_csv(\"deseason.csv\") \n",
    "df = np.array(dfP)[0:301,0:50] #Only use part of the data\n",
    "### \"Data preprocessing\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "N = 50\n",
    "output_size = 50\n",
    "Smp_size = 200\n",
    "q = 1 #hidden dimension\n",
    "lag =  30\n",
    "Pred_size = len(df)-Smp_size-lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {}\n",
    "names[\"predErrorLSTM1\"] =  []\n",
    "names[\"predErrorLSTM1Linf\"] =  []\n",
    "names[\"LTRLSTM1_pred\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "# initialization\n",
    "p , q, output_size= (N, 1, N)\n",
    "\n",
    "# transform the time series involving\n",
    "def create_dataset(y, look_back=1):\n",
    "    dataYp,dataYc = [], [] #Ypast, Ycurrent\n",
    "    for i in range(len(y)-look_back):\n",
    "        dataYp.append(y[i,:])\n",
    "        dataYc.append(y[i+look_back, :])\n",
    "    return np.array(dataYp), np.array(dataYc)\n",
    " \n",
    "# transform data to tensor in torch\n",
    "def to_torch(state):\n",
    "    state = torch.from_numpy(state).float()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredError is 0.7176728001988969.\n",
      "PredErrorLinf is 0.21635815920688573.\n",
      "0\n",
      "PredError is 0.9882425359681117.\n",
      "PredErrorLinf is 0.5267095863819122.\n",
      "1\n",
      "PredError is 0.7272523168882075.\n",
      "PredErrorLinf is 0.4662946611116001.\n",
      "2\n",
      "PredError is 0.7399843275535557.\n",
      "PredErrorLinf is 0.3105925238505819.\n",
      "3\n",
      "PredError is 0.5694433487317677.\n",
      "PredErrorLinf is 0.22930148767156344.\n",
      "4\n",
      "PredError is 0.6581486607279747.\n",
      "PredErrorLinf is 0.37750381121405213.\n",
      "5\n",
      "PredError is 0.7732663756198289.\n",
      "PredErrorLinf is 0.3462914518879225.\n",
      "6\n",
      "PredError is 0.9801099633825588.\n",
      "PredErrorLinf is 0.48707252740859985.\n",
      "7\n",
      "PredError is 0.7699922491329393.\n",
      "PredErrorLinf is 0.32172202135006595.\n",
      "8\n",
      "PredError is 0.512143244400923.\n",
      "PredErrorLinf is 0.21876814109067838.\n",
      "9\n",
      "Elapsed time during the whole program in seconds: 1079.3751248730005\n"
     ]
    }
   ],
   "source": [
    "distance = L2LossFun()\n",
    "distanceLinf = LinfLossFun()\n",
    "\n",
    "t1_start = perf_counter() \n",
    "\n",
    "for k in range(pred_size):\n",
    "    y = df[(Smp_size+k+lag-200):(Smp_size+k+lag+1),:] #Fixed size at 200! Need to readjust\n",
    "    inY, outY = create_dataset(y=y, look_back=1)\n",
    "    # split into train and test sets\n",
    "    train_size = 200                                  #Fixed size at 200! Need to readjust\n",
    "    test_size = 1\n",
    "    trainInY,trainOutY = inY[0:train_size-1], outY[0:train_size-1]\n",
    "    testInY,testOutY =  inY[train_size-1:], outY[train_size-1:]\n",
    "    trainInY = np.reshape(trainInY, (trainInY.shape[0], p))\n",
    "    trainOutY = np.reshape(trainOutY, (trainOutY.shape[0], p))\n",
    "    testInY = np.reshape(testInY, (testInY.shape[0], p))\n",
    "    testOutY = np.reshape(testOutY, (testOutY.shape[0], p))\n",
    "\n",
    "    model = LSTM(p = N,q = 1, output_size = output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "    loss_last = 1000\n",
    "    loss_new = 0\n",
    "\n",
    "    i = 0\n",
    "    while abs(loss_last - loss_new)  > 0.000001:\n",
    "        if i > 0:\n",
    "            loss_last = loss_new  \n",
    "\n",
    "        model.zero_grad()\n",
    "        target = torch.from_numpy(trainOutY).float()\n",
    "        output,_,_ = model(torch.from_numpy(trainInY).float())\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output,c,h = model(torch.from_numpy(trainInY).float())\n",
    "        loss_new = loss.item()\n",
    "        i = i + 1\n",
    "        #print(loss_new)\n",
    "    testPredict,_,_ = model(torch.from_numpy(testInY).float(), h, c)\n",
    "    testPredict = testPredict.detach().numpy()\n",
    "    # invert predictions\n",
    "    #testPredict_r = scaler.inverse_transform(testPredict[:,:])\n",
    "    #testY_r = scaler.inverse_transform(testOutY[:,:])\n",
    "    names[\"LTRLSTM1_pred\"].append(testPredict)\n",
    "    predError = distance(testPredict, testOutY)\n",
    "    names[\"predErrorLSTM1\"].append(predError)\n",
    "    print(\"PredError is {}.\".format(predError))\n",
    "    predErrorLinf = distanceLinf(testPredict, testOutY)\n",
    "    names[\"predErrorLSTM1Linf\"].append(predErrorLinf)\n",
    "    print(\"PredErrorLinf is {}.\".format(predErrorLinf))\n",
    "    \n",
    "    print(k)\n",
    "\n",
    "t1_stop = perf_counter() \n",
    "print(\"Elapsed time during the whole program in seconds:\", \n",
    "                                        t1_stop-t1_start) \n",
    "Real_200LSTM1s_2 = names\n",
    "torch.save(Real_200LSTM1s_2, \"Real_200LSTM1s_2.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
